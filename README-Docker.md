# ğŸ³ DGU Futebol - ExecuÃ§Ã£o com Docker

Este guia explica como executar o pipeline de dados de futebol usando Docker.

## ğŸ“‹ PrÃ©-requisitos

1. **Docker** e **Docker Compose** instalados
2. **Credenciais do BigQuery** (arquivo JSON)
3. **Arquivo profiles.yml** configurado

## ğŸš€ ConfiguraÃ§Ã£o RÃ¡pida

### 1. Preparar Credenciais

```bash
# Criar diretÃ³rio para credenciais
mkdir -p credentials

# Copiar seu arquivo de credenciais do BigQuery
cp /caminho/para/suas/credenciais.json credentials/bigquery-credentials.json
```

### 2. Configurar profiles.yml

```bash
# Copiar o exemplo
cp DGU/profiles.yml.example DGU/profiles.yml

# Editar com suas configuraÃ§Ãµes
nano DGU/profiles.yml
```

Exemplo de configuraÃ§Ã£o:
```yaml
DGU:
  target: dev
  outputs:
    dev:
      type: bigquery
      method: service-account
      keyfile: /app/credentials/bigquery-credentials.json
      project: seu-project-id
      dataset: DataGlowUp
      threads: 4
      timeout_seconds: 300
      location: US
      priority: interactive
      retries: 1
```

### 3. Executar o Pipeline

```bash
# Construir e executar
docker-compose up --build

# Ou executar em background
docker-compose up -d --build
```

## ğŸ“Š Comandos Ãšteis

### Pipeline Completo
```bash
# Executar pipeline completo (extraÃ§Ã£o + dbt)
docker-compose run --rm dgu-futebol python main.py
```

### Comandos dbt Manuais
```bash
# Executar apenas seeds
docker-compose run --rm dgu-futebol bash -c "cd DGU && dbt seed --profiles-dir ."

# Executar apenas staging
docker-compose run --rm dgu-futebol bash -c "cd DGU && dbt run --select staging --profiles-dir ."

# Executar apenas mart
docker-compose run --rm dgu-futebol bash -c "cd DGU && dbt run --select mart --profiles-dir ."

# Executar testes
docker-compose run --rm dgu-futebol bash -c "cd DGU && dbt test --profiles-dir ."
```

### Comandos de Debug
```bash
# Acessar shell do container
docker-compose run --rm dgu-futebol bash

# Ver logs em tempo real
docker-compose logs -f dgu-futebol

# Verificar status dos containers
docker-compose ps
```

## ğŸ“ Estrutura de Volumes

```
projeto/
â”œâ”€â”€ credentials/
â”‚   â””â”€â”€ bigquery-credentials.json  # Suas credenciais (nÃ£o commitadas)
â”œâ”€â”€ logs/                          # Logs persistidos
â”œâ”€â”€ DGU/
â”‚   â”œâ”€â”€ seeds/                     # CSVs gerados
â”‚   â””â”€â”€ profiles.yml               # ConfiguraÃ§Ã£o dbt
â””â”€â”€ docker-compose.yml
```

## ğŸ”§ PersonalizaÃ§Ã£o

### VariÃ¡veis de Ambiente

VocÃª pode personalizar o comportamento atravÃ©s de variÃ¡veis de ambiente:

```bash
# Arquivo .env (opcional)
PROJECT_ID=seu-project-id
DATASET_ID=SeuDataset
```

### Recursos do Container

Edite `docker-compose.yml` para ajustar recursos:

```yaml
deploy:
  resources:
    limits:
      memory: 4G      # Aumentar se necessÃ¡rio
      cpus: '2.0'
```

## ğŸ› SoluÃ§Ã£o de Problemas

### Erro de Credenciais
```bash
# Verificar se o arquivo existe
ls -la credentials/

# Verificar permissÃµes
chmod 600 credentials/bigquery-credentials.json
```

### Erro de ConexÃ£o BigQuery
```bash
# Testar conexÃ£o manualmente
docker-compose run --rm dgu-futebol python -c "
from google.cloud import bigquery
client = bigquery.Client()
print('ConexÃ£o OK!')
"
```

### Limpar Ambiente
```bash
# Parar containers
docker-compose down

# Remover volumes (cuidado!)
docker-compose down -v

# Limpar imagens
docker system prune -a
```

## ğŸ“ˆ Monitoramento

### Ver Progresso
```bash
# Logs em tempo real
docker-compose logs -f

# Status dos containers
docker-compose ps

# Uso de recursos
docker stats
```

### Verificar Resultados
ApÃ³s a execuÃ§Ã£o, verifique no BigQuery Console:
- Dataset `DataGlowUp` (dados brutos)
- Dataset `DataGlowUp_staging` (views)
- Dataset `DataGlowUp_mart` (tabelas finais)

## ğŸ”„ ExecuÃ§Ã£o Agendada

Para execuÃ§Ã£o automÃ¡tica, vocÃª pode usar cron:

```bash
# Adicionar ao crontab
0 6 * * * cd /caminho/do/projeto && docker-compose run --rm dgu-futebol python main.py
```

## ğŸ“š PrÃ³ximos Passos

1. Configure alertas de monitoramento
2. Implemente backup dos dados
3. Configure CI/CD para atualizaÃ§Ãµes automÃ¡ticas
4. Adicione mais fontes de dados

---

**ğŸ† Pipeline de dados de futebol containerizado e pronto para produÃ§Ã£o!**

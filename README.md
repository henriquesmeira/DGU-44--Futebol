# ğŸ† Projeto DGU - Pipeline de Dados de Futebol

Pipeline completo de extraÃ§Ã£o, transformaÃ§Ã£o e anÃ¡lise de dados de futebol dos principais times brasileiros usando Python, dbt e BigQuery.

## âš™ï¸ ConfiguraÃ§Ã£o Inicial

1. **Configure o profiles.yml:**
   ```bash
   cp DGU/profiles.yml.example DGU/profiles.yml
   # Edite DGU/profiles.yml com suas credenciais
   ```

2. **Adicione suas credenciais BigQuery** no diretÃ³rio raiz

## ğŸš€ ExecuÃ§Ã£o

### ğŸ¤– OpÃ§Ã£o 1: Apache Airflow 3.0 (Recomendado para ProduÃ§Ã£o)

```bash
# Configurar credenciais
mkdir -p credentials
cp /caminho/para/suas/credenciais.json credentials/bigquery-credentials.json

# Configurar profiles.yml
cp DGU/profiles.yml.example DGU/profiles.yml
# Editar DGU/profiles.yml com suas configuraÃ§Ãµes

# Inicializar Airflow
./docker-scripts.sh init-airflow

# Acessar interface web
http://localhost:8080 (usuÃ¡rio: airflow, senha: airflow)
```

**ğŸ• ExecuÃ§Ã£o AutomÃ¡tica**: TerÃ§as e sextas Ã s 09:00
ğŸ“– **DocumentaÃ§Ã£o completa**: [README-AIRFLOW.md](README-AIRFLOW.md)

### ğŸ³ OpÃ§Ã£o 2: Docker Standalone

```bash
# Configurar credenciais (mesmo processo acima)

# Executar pipeline completo
docker-compose up --build
```

ğŸ“– **DocumentaÃ§Ã£o completa**: [README-Docker.md](README-Docker.md)

### ğŸ OpÃ§Ã£o 3: Ambiente Local

```bash
# Ativar ambiente virtual
source dbt-env/bin/activate

# Executar pipeline completo
python main.py
```

## ğŸ“Š O que o Pipeline Faz

1. **ğŸ“ˆ Extrai dados reais** do fbref.com e transfermarkt.com
2. **ğŸ’¾ Salva como seeds** CSV para o dbt
3. **ğŸŒ± Carrega no BigQuery** (dataset DataGlowUp)
4. **ğŸ”„ Cria views staging** (dataset DataGlowUp_staging)
5. **ğŸ“Š Cria tabelas mart** (dataset DataGlowUp_mart)

## ğŸ¯ Dados Coletados

### Times Analisados:
- **Palmeiras** âš½
- **Flamengo** âš½  
- **Corinthians** âš½

### MÃ©tricas ExtraÃ­das:
- **EstatÃ­sticas dos jogadores**: Gols, assistÃªncias, cartÃµes, xG, xA
- **Valores de mercado**: PreÃ§os em euros, contratos, posiÃ§Ãµes
- **AnÃ¡lises agregadas**: Resumos por time, classificaÃ§Ãµes

## ğŸ“ Estrutura do Projeto

```
â”œâ”€â”€ main.py                    # ğŸš€ Script principal
â”œâ”€â”€ extract.py                 # ğŸ“Š ExtraÃ§Ã£o de dados
â”œâ”€â”€ load.py                    # ğŸ“¤ Carregamento BigQuery
â”œâ”€â”€ dataglowup-*.json         # ğŸ”‘ Credenciais
â”œâ”€â”€ dbt-env/                   # ğŸ Ambiente Python
â””â”€â”€ DGU/                       # ğŸ“¦ Projeto dbt
    â”œâ”€â”€ seeds/                 # ğŸ“„ Dados CSV
    â”œâ”€â”€ models/staging/        # ğŸ”„ Views limpas
    â””â”€â”€ models/mart/           # ğŸ“Š Tabelas finais
```

## ğŸ“ˆ Resultados no BigQuery

### Dataset `DataGlowUp` (Seeds)
- 6 tabelas com dados brutos extraÃ­dos

### Dataset `DataGlowUp_staging` (Views)  
- 6 views com dados limpos e padronizados

### Dataset `DataGlowUp_mart` (Tabelas)
- `mart_players_stats` - EstatÃ­sticas consolidadas
- `mart_players_market_value` - AnÃ¡lise de valores
- `mart_teams_summary` - Resumo por time

## ğŸ› ï¸ Tecnologias

- **Apache Airflow 3.0** - OrquestraÃ§Ã£o e agendamento
- **Python** - ExtraÃ§Ã£o e processamento
- **dbt** - TransformaÃ§Ã£o de dados
- **BigQuery** - Data warehouse
- **Pandas** - ManipulaÃ§Ã£o de dados
- **BeautifulSoup** - Web scraping
- **Docker** - ContainerizaÃ§Ã£o e deploy
- **PostgreSQL** - Banco de dados do Airflow

## ğŸ“š DocumentaÃ§Ã£o Completa

Veja `PROJETO_COMPLETO.md` para documentaÃ§Ã£o detalhada.

---

**Desenvolvido para anÃ¡lise de dados de futebol brasileiro** âš½ğŸ‡§ğŸ‡·
